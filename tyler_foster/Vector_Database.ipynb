{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da185a4c-3213-47b5-9426-e8c34b0ec413",
   "metadata": {},
   "source": [
    "# Vector Database Example.\n",
    "Modified version of the notebook that appears in [this Medium article](https://arupnanda.medium.com/lowdown-on-vector-databases-ec39fe70a17). The article is Part 2 in a 3-part series that provides a good intro to vector databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71302ec2-9bae-4fa4-8622-852d21fbcc70",
   "metadata": {},
   "source": [
    "## Initial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1eda3b-5617-4fad-b689-c020d065a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Hugging Face dataset library\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9c32b-9441-4e16-865c-6f528451a6d0",
   "metadata": {},
   "source": [
    "We use the dataset `wiki_qa`, called the \"WikiQA Corpus,\" and is provided by Microsoft. Find the official documentation [here](https://huggingface.co/datasets/wiki_qa). Records in this dataset correspond to single questions/answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da54267-f40d-4d8c-b206-806b72dac2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('wiki_qa', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe6717-af3b-4da4-9e8d-72d804bad523",
   "metadata": {},
   "source": [
    "Here are the first 5 entries in the dataset. Note the `'label'` key. It seems to indicate how well the answer addresses the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f088e-aa4a-4abe-a205-c19510abce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five = ds[:5]\n",
    "for i in range(5):\n",
    "    print('\\nRECORD {}'.format(i))\n",
    "    for key in first_five:\n",
    "        print(key, ':', first_five[key][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431bdc4e-fe2c-495a-9445-52008c0ec797",
   "metadata": {},
   "source": [
    "We collect just the questions in this dataset, and remove duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c648530-a377-48bd-8d3d-84a079761712",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for i in ds ['question']:\n",
    "    questions.append(i)\n",
    "\n",
    "questions = list(set(questions))\n",
    "\n",
    "print('\\nNumber of unique questions:', len(questions), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4125d791-1ebf-495b-bc03-f015eb8d55b5",
   "metadata": {},
   "source": [
    "Questions 0 through 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e456ce-ed49-4b24-897a-eef1fe74e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74368ff-226d-4ada-9441-60618474f8c9",
   "metadata": {},
   "source": [
    "## ChromaDB.\n",
    "ChromaDB is an \"open-source embedding database,\" i.e., an opensource vector database that makes you of vector embeddings. Find the official documentatino [here](https://docs.trychroma.com/getting-started). If you do not already have the ChromaDB library, run `!pip install chromadb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846442b9-d29a-47e9-acd3-6e47848dc173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4f358-8dd6-427d-b8f2-999f1c9fb0e2",
   "metadata": {},
   "source": [
    "Create *Client* object for interacting with the database: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35d532-beec-4fd4-814f-7c3467a61a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a3b3c-55d1-446d-b9e2-6e80da92652d",
   "metadata": {},
   "source": [
    "Create a new collection, called `'my_collection'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a945d5-729f-4a07-8f92-4d45cb846d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_collection = client.create_collection(name='my_collection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5aa503-0291-4dc2-9587-b4859655b308",
   "metadata": {},
   "source": [
    "### Set up embeddings.\n",
    "We will need:\n",
    "1. An ID for the record.\n",
    "2. A \"document\", namely the question we collected.\n",
    "3. A vector representation of the document, i.e., a vector embedding.\n",
    "\n",
    "We will encode questions using a model in the Hugging Face *Sentence Transformers* library. Find official documentation [here](https://www.sbert.net/#). If you haven't installed this library, run `!pip install -U sentence-transformers`. **Note:** I had to update my Hugging Face Hub as well by running `!pip install --upgrade huggingface_hub`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2db6a6-4e30-486a-af13-820cf6faef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm # For trakcing runtime\n",
    "from sentence_transformers import SentenceTransformer # Hugging Face's Sentence Transformer library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c02279-b5dd-4e55-beed-411af1fff4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3987a73b-0feb-40c0-b020-3261d0e94aff",
   "metadata": {},
   "source": [
    "Upsert (i,.e., update or insert, depending on case) to `'my_collection'` in batches of size 128:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a57257-082d-4da5-b934-8f705f8f0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "total_size=2118\n",
    "for ctr in tqdm(range(0,total_size,batch_size)):\n",
    "    ctr_end = min(ctr+batch_size, total_size)\n",
    "    IDs = [str(i) for i in range(ctr, ctr_end)]\n",
    "    documents = [text for text in questions[ctr:ctr_end]]\n",
    "    embeddings = model.encode(questions[ctr:ctr_end]).tolist() # Here we encode each question as a vector\n",
    "    my_collection.upsert(documents=documents, ids=IDs, embeddings=embeddings)\n",
    "\n",
    "print('\\nDatabase contains {} distinct records.\\n'.format(my_collection.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d46807-5fc4-4ce1-ae4c-2d4844fe2210",
   "metadata": {},
   "source": [
    "### Query execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bbfacb-9c17-41dd-93a1-fbacd3970f75",
   "metadata": {},
   "source": [
    "Supose we want to ask a question that might not be in the database. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b62e589-6187-45b5-81fa-cb29e17a0688",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'why did Americans fight their own'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e541285-61de-4add-99e3-fb161f9b66dc",
   "metadata": {},
   "source": [
    "Think of this `question` as being our query. We do part of the query processing by hand. Namely, we encode the question as a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658b9bc-ebd2-4da3-a7ad-6c9a4a0103f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vector = model.encode(question).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37522301-22ed-49b9-8c86-6600d6994514",
   "metadata": {},
   "source": [
    "...The rest of the query execution can now be done by the vector database. The `.query()` method we use here returns a Python dictionary. The key `'documents'` pulls the documents associated to the \"nearest records\" to our `question`. These approximate questions are the *values* output by the databases query execution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90799d36-346d-4f07-bdd5-7986fa3388e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_vectors = my_collection.query(question_vector, n_results = 3)\n",
    "\n",
    "for n, entry in enumerate(similar_vectors['documents'][0]):\n",
    "    print('Closest question {count}: \\'{question}\\''.format(count = n, question = entry))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea0145-fc7d-4201-854e-2dec725154e6",
   "metadata": {},
   "source": [
    "Finer data about the values we retrieved, including distances for the vectors in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf2796-a413-4535-bf86-a14bdc054783",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"Distance\":>8} {\"ID\":>4} {\"Question\"}') # Print table header\n",
    "for ids in similar_vectors['ids'][0]: # Cycle through query output\n",
    "    i = similar_vectors['ids'][0].index(ids)\n",
    "    print(f\"{round(similar_vectors['distances'][0][i],6):1.6f} {ids:>4} {similar_vectors['documents'][0][i]}\") # Print table row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf3524-2c15-4a33-a56d-dc3407635fd5",
   "metadata": {},
   "source": [
    "### Deleting your collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486af15e-c479-41b9-8ff9-64bbb3525bb5",
   "metadata": {},
   "source": [
    "**WARNING:** Running the following cell will delete the collection `'my_collection'` that you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44950d6e-bdb3-4672-b894-c9b5adbb331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(name='my_collection')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
